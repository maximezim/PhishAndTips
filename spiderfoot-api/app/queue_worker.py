# queue_worker.py
import threading
import time
import uuid
import json
import subprocess
import os
import re

from app.database import SessionLocal
from app.models import SpiderfootScan

# A simple in-memory queue
scan_queue = []

def fetch_scan_data(spiderfoot_scan_id: str):
    """
    Fetch parsed "data" from SpiderFoot using the CLI and parse results into JSON.
    """
    data_commands = f"data {spiderfoot_scan_id}\nexit\n"
    data_cmd = [
        "python3",
        "/opt/spiderfoot/sfcli.py",
        "-s", "http://spiderfoot:5001"
    ]

    data_process = subprocess.Popen(
        data_cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True
    )
    data_stdout, data_stderr = data_process.communicate(data_commands)

    if data_process.returncode != 0:
        return {"error": f"Error fetching data: {data_stderr.strip()}"}

    lines = data_stdout.splitlines()
    results = []
    sep_index = None
    for i, line in enumerate(lines):
        if re.match(r"^-+(\+)-+$", line.replace(' ', '')):
            sep_index = i
            break

    if sep_index is None:
        return {"error": "Failed to parse data output."}

    data_lines = lines[sep_index+1:]
    for l in data_lines:
        l = l.strip()
        if not l:
            continue
        parts = l.rsplit('|', 1)
        if len(parts) == 2:
            data_val = parts[0].strip()
            type_val = parts[1].strip()
            results.append({"Data": data_val, "Type": type_val})

    return {"count": len(results), "results": results}


def run_spiderfoot_scan(scan_id: uuid.UUID, target: str, modules: str):
    command_log_file = f"/tmp/{scan_id}_commands.log"
    output_file = f"/tmp/{scan_id}.json"

    commands = f"start {target} -u all -n {scan_id}\nexit\n"
    cmd = [
        "python3",
        "/opt/spiderfoot/sfcli.py",
        "-s", "http://spiderfoot:5001",
        "-o", command_log_file
    ]

    spiderfoot_scan_id = None

    try:
        process = subprocess.Popen(
            cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        stdout, stderr = process.communicate(commands)

        if process.returncode != 0:
            result_data = {"error": f"SpiderFoot CLI error: {stderr.strip()}"}
        else:
            match = re.search(r"Scan ID:\s+([A-Za-z0-9]+)", stdout)
            if match:
                spiderfoot_scan_id = match.group(1)
                result_data = {
                    "message": "Scan started successfully.",
                    "spiderfoot_scan_id": spiderfoot_scan_id
                }
            else:
                result_data = {"error": "Failed to parse SpiderFoot scan ID."}

            if os.path.exists(command_log_file):
                os.remove(command_log_file)

        db = SessionLocal()
        scan = db.query(SpiderfootScan).filter(SpiderfootScan.target == target).first()
        if scan:
            scan.status = "running"
            scan.result = result_data
            if spiderfoot_scan_id:
                scan.spiderfoot_scan_id = spiderfoot_scan_id
            db.commit()
        db.close()

        if not spiderfoot_scan_id:
            return

        # Wait for the scan to complete
        time.sleep(120)

        export_commands = f"export {spiderfoot_scan_id} -t json -f {output_file}\nexit\n"
        export_cmd = [
            "python3",
            "/opt/spiderfoot/sfcli.py",
            "-s", "http://spiderfoot:5001",
            "-o", f"/tmp/{scan_id}_export.log"
        ]

        export_process = subprocess.Popen(
            export_cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        export_stdout, export_stderr = export_process.communicate(export_commands)

        if export_process.returncode != 0:
            export_result = {"error": f"SpiderFoot export error: {export_stderr.strip()}"}
        else:
            if os.path.exists(output_file):
                with open(output_file, 'r') as f:
                    try:
                        export_data = json.load(f)
                        export_result = export_data
                    except json.JSONDecodeError:
                        export_result = {"error": "Failed to parse SpiderFoot export JSON."}
                os.remove(output_file)
                export_log_file = f"/tmp/{scan_id}_export.log"
                if os.path.exists(export_log_file):
                    os.remove(export_log_file)
            else:
                export_result = {"error": "No output file generated by SpiderFoot export."}

        db = SessionLocal()
        scan = db.query(SpiderfootScan).filter(SpiderfootScan.target == target).first()
        if scan:
            scan.status = "completed"
            scan.result = export_result
            db.commit()
        db.close()

        # Fetch parsed data
        data_result = fetch_scan_data(spiderfoot_scan_id)

        db = SessionLocal()
        scan = db.query(SpiderfootScan).filter(SpiderfootScan.target == target).first()
        if scan:
            if isinstance(scan.result, dict):
                scan.result["parsed_data"] = data_result
            else:
                scan.result = {"export_result": export_result, "parsed_data": data_result}
            db.commit()
        db.close()

    except Exception as e:
        db = SessionLocal()
        scan = db.query(SpiderfootScan).filter(SpiderfootScan.target == target).first()
        if scan:
            scan.status = "error"
            scan.result = {"error": str(e)}
            db.commit()
        db.close()


def queue_worker():
    while True:
        if scan_queue:
            scan_info = scan_queue.pop(0)
            target = scan_info["target"]
            new_scan_id = scan_info["id"]
            modules = scan_info.get("modules", "")

            db = SessionLocal()
            scan = db.query(SpiderfootScan).filter(SpiderfootScan.target == target).first()
            if scan:
                scan.status = "running"
                db.commit()
            db.close()

            run_spiderfoot_scan(new_scan_id, target, modules)
        else:
            time.sleep(2)

worker_thread = threading.Thread(target=queue_worker, daemon=True)
worker_thread.start()
